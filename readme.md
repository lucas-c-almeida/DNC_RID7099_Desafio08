# Contexto

Este projeto faz parte da P√≥s Gradua√ß√£o em Engenharia de dados pela DNC e Sirius. Utilizamos Apache Airflow e Pandas para estruturar os dados conforme o solicitado:


# Desafio: **Construindo um Pipeline de Dados com Python**

# üöÄ Desafio

<aside>
üìé **Arquivos do Desafio:**

- **Python** para processamento e transforma√ß√µes de dados.
- **Apache Airflow** para orquestrar o pipeline.
- **Docker** para executar o Airflow em um cont√™iner, isolando suas depend√™ncias e ambiente:
- **Base de dados:**
    
    [raw_data.csv](https://prod-files-secure.s3.us-west-2.amazonaws.com/6a055055-52ec-4ebb-a697-63027c951344/109745a7-935b-4e00-9635-834d94ee4913/raw_data.csv)
    
</aside>

## **Contexto:**

Na era da transforma√ß√£o digital, dados precisos s√£o essenciais para empresas como a "DncInsight Solutions", especializada em an√°lise e processamento de dados. A empresa enfrenta desafios com a qualidade e organiza√ß√£o dos dados recebidos, muitas vezes inconsistentes e incompletos. Para resolver isso, "DncInsight Solutions" iniciou um desafio interno para desenvolver um sistema robusto e automatizado para o processamento de dados.

Como engenheiro de dados na "DncInsight Solutions", voc√™ √© respons√°vel por desenvolver um pipeline de dados usando Apache Airflow. Este pipeline transformar√° dados brutos em insights valiosos atrav√©s de um processo que inclui a limpeza e agrega√ß√£o de dados. Diferentemente da abordagem tradicional com AWS S3, voc√™ simular√° um ambiente de produ√ß√£o usando pastas locais para armazenamento de dados.

## Como come√ßar?

Sua tarefa √© projetar e implementar um pipeline de dados que ingere dados brutos, os processa e os armazena em tr√™s camadas distintas (bronze, prata e ouro) . O pipeline deve ser orquestrado usando o Apache Airflow. Lembre-se, o Windows n√£o suporta o Airflow, sugerimos a utiliza√ß√£o de Docker para executar o Airflow.

# üéØ Etapas de Desenvolvimento

## **Etapa 01) Configura√ß√£o Inicial**

Configure o Apache Airflow usando Docker para criar um ambiente uniforme e controlado. Esta configura√ß√£o inicial garante consist√™ncia nas depend√™ncias e facilita o gerenciamento de seu pipeline de dados.

### **Passos R√°pidos para Configura√ß√£o:**

- **Instale o Docker Desktop**: Dispon√≠vel para [download](https://www.docker.com/products/docker-desktop/) no site oficial do Docker.
- **Organize as Pastas de Dados**: Estruture pastas locais para Bronze, Prata e Ouro para simular as camadas de armazenamento de dados.
- **Configure e Inicie o Airflow com Docker Compose**: Defina o servi√ßo do Airflow no Docker Compose e inicie-o para acessar a interface web em `http://localhost:8080`.

<aside>
üí° **Dica**: Instale bibliotecas essenciais como **`pandas`** dentro do cont√™iner do Airflow para a manipula√ß√£o de dados.

</aside>

## **Etapa 02) Criando o DAG no Airflow**

**Desenvolvimento do DAG:**

- Criar um DAG no Airflow que ir√° orquestrar todas as opera√ß√µes do pipeline de dados desde o carregamento at√© a transforma√ß√£o final.
- Definir tarefas sequenciais dentro do DAG para manipula√ß√£o dos dados em cada camada.

<aside>
üí° **Dica:** Ao configurar o DAG, mantenha a legibilidade e a manutenibilidade em mente. Nomeie claramente cada tarefa e certifique-se de que as depend√™ncias entre as tarefas est√£o bem definidas para evitar ciclos e erros de execu√ß√£o.

</aside>

## Etapa 03) Processamento e Limpeza de dados

- **Carregar Dados Brutos na Camada Bronze:**
    - Implementar a fun√ß√£o `upload_raw_data_to_bronze` para carregar dados brutos nos formatos CSV para a camada Bronze.
- **Limpeza de Dados para a Camada Prata:**
    - Utilizar a fun√ß√£o `process_bronze_to_silver` para ler e limpar os dados da camada Bronze:
        - Remover registros com campos nulos (nome, email, data de nascimento).
        - Corrigir formatos de email inv√°lidos. (para ser um email valido √© necess√°rio ter o caracter ‚Äú@‚Äù)
        - Calcular a idade dos usu√°rios com base na data de nascimento.

<aside>
üí° **Dica**: Para as fun√ß√µes de limpeza de dados, considere usar express√µes lambda e fun√ß√µes do pandas para efici√™ncia. Por exemplo, ao verificar emails v√°lidos, uma express√£o lambda combinada com a fun√ß√£o `apply` pode ser muito mais r√°pida do que um loop tradicional.

</aside>

## **Etapa 04) Transforma√ß√£o e Armazenamento de Dados**

1. **Transforma√ß√µes para a Camada Ouro:**
    - Com a fun√ß√£o `process_silver_to_gold`, ler os dados da camada Prata.
    - Executar transforma√ß√µes adicionais:
        - Agregar os dados por faixa et√°ria e status (ativo ou inativo), facilitando an√°lises demogr√°ficas e comportamentais.
        - Crie um dataset que mostre o n√∫mero de usu√°rios por faixa et√°ria (0 a 10, 11 a 20, 21 a 30 anos‚Ä¶) e por status (‚Äúactive‚Äù ou ‚Äúinactive‚Äù)
    - Salvar os dados transformados na camada Ouro, prontos para an√°lise e uso em decis√µes estrat√©gicas.

<aside>
üí° **Dica:** Ao realizar opera√ß√µes de agrega√ß√£o como no processamento para a camada Ouro, use m√©todos otimizados da biblioteca **`pandas`** como **`groupby`** ou `cut` para classificar e agrupar dados. Essas fun√ß√µes s√£o otimizadas internamente para lidar com grandes volumes de dados mais eficientemente do que implementa√ß√µes manuais.

</aside>

---

# üìù Crit√©rios de Avalia√ß√£o

Os crit√©rios de avalia√ß√£o mostram como voc√™ ser√° avaliado em rela√ß√£o ao seu desafio. 

| **Crit√©rios** | **Atendeu √†s Especifica√ß√µes** | Pontos |
| --- | --- | --- |
| **Configura√ß√£o e organiza√ß√£o de pastas** | Verifica se as pastas de dados foram corretamente criadas e organizadas para simular as camadas de armazenamento (Bronze, Prata, Ouro). Avalia a clareza na estrutura√ß√£o e se as pastas est√£o configuradas para facilitar o acesso e a manipula√ß√£o dos dados dentro do ambiente Docker. | **25** |
| **Camada Bronze** | Nessa etapa o aluno dever√° implementar a fun√ß√£o upload_raw_data_to_bronze para carregar os dados brutos. Verifica se os dados brutos s√£o corretamente carregados na camada Bronze e se a integridade dos dados √© mantida. | **25** |
| **Camada Prata** | Nessa etapa o aluno dever√° realizar a efic√°cia das opera√ß√µes de limpeza de dados na camada Prata. Inclui a remo√ß√£o de registros com campos nulos e a corre√ß√£o de e-mails inv√°lidos. Verifica tamb√©m a correta implementa√ß√£o das transforma√ß√µes como o c√°lculo da idade dos usu√°rios. | **25** |
| **Camada Ouro** | Nessa etapa o aluno dever√° realizar as transforma√ß√µes para a prepara√ß√£o dos dados para an√°lises avan√ßadas. Inclui a agrega√ß√£o dos dados por faixa et√°ria e status e o correto armazenamento dos dados na camada Ouro, verificando se est√£o prontos para uso em decis√µes estrat√©gicas. | **25** |

# üìÜ Entrega

<aside>
‚ö†Ô∏è **Atente-se a forma de nomear o REPOSIT√ìRIO: ele deve contar com o seu RID. Exemplo: (RID01234_Desafio08). O RID pode ser encontrado dentro da sua plataforma em "meu perfil‚Äù e √© composto por 5 n√∫meros.**

</aside>

<aside>
üìé **Como entregar:** O aluno deve entregar o projeto atrav√©s do link do reposit√≥rio do Github ou um arquivo zipado.

</aside>

### Atente-se ao formato de entrega deste desafio!

1. Nomeie o seu colab com o RID e o n√∫mero do desafio. Exemplo: RID1234_Desafio01
2. V√° em Arquivo > Fazer download > Baixar o .ipynb
3. Fa√ßa o upload do arquivo no drive
4. Altere as configura√ß√µes do arquivo para deix√°-lo p√∫blico. 
5. Copie o link ap√≥s alterar a permiss√£o de acesso.
6. Submeta o link do arquivo (e n√£o da pasta do drive!) na plataforma. 

Se ainda houver d√∫vidas, assista ao gif abaixo:

![GravacÃßaÃÉo de Tela 2025-01-28 aÃÄs 11.14.35.gif](attachment:0dfa253c-e111-431a-b76f-85cba55797b4:Gravacao_de_Tela_2025-01-28_as_11.14.35.gif)